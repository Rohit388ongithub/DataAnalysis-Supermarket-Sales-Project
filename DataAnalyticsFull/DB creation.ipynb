{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95e98045-d0b9-4679-a3e5-79a62bb328ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymysql in c:\\users\\rohit\\anaconda3\\lib\\site-packages (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymysql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cb175c8-0eeb-46d0-8b84-00d8066d7218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: PyMySQL\n",
      "Version: 1.1.1\n",
      "Summary: Pure Python MySQL Driver\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: Inada Naoki <songofacandy@gmail.com>, Yutaka Matsubara <yutaka.matsubara@gmail.com>\n",
      "License: MIT License\n",
      "Location: C:\\Users\\rohit\\anaconda3\\Lib\\site-packages\n",
      "Requires: \n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show pymysql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5f1a54e-97ab-4ee2-9723-297d0808e8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL query generated and saved to output.sql\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Path to your CSV file\n",
    "csv_file = 'c:/users/rohit/downloads/project/clean_sales.csv'\n",
    "\n",
    "# Columns in the CSV (use the correct names from your CSV file)\n",
    "columns = ['Order_ID', 'Order_Date', 'Ship Mode', 'Segment', 'City', 'State', 'Region', 'Category', 'Sales']\n",
    "\n",
    "# Open and read the CSV file\n",
    "with open(csv_file, mode='r') as file:\n",
    "    csv_reader = csv.DictReader(file)\n",
    "    \n",
    "    # Prepare the insert statement\n",
    "    insert_statement = f\"INSERT INTO clean_sales ({', '.join(columns)}) VALUES \\n\"\n",
    "    \n",
    "    # Prepare values list\n",
    "    values_list = []\n",
    "    for row in csv_reader:\n",
    "        # Extract values from the CSV, ensuring proper formatting (skip Sales column formatting)\n",
    "        values = [f\"'{row[col]}'\" if col != \"Sales\" else row[col] for col in columns]\n",
    "        values_list.append(f\"({', '.join(values)})\")\n",
    "    \n",
    "    # Join all the values with commas, separating each row's values\n",
    "    final_values = \",\\n\".join(values_list)\n",
    "    \n",
    "    # Complete SQL query (just one INSERT INTO with multiple rows of values)\n",
    "    sql_query = insert_statement + final_values + \";\"\n",
    "    \n",
    "    # Write the SQL query to a file\n",
    "    with open('output.sql', mode='w') as output_file:\n",
    "        output_file.write(sql_query)\n",
    "\n",
    "print(\"SQL query generated and saved to output.sql\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4abc187-431d-425f-bb52-7f91c8bda996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL query generated and saved to: c:/users/rohit/downloads/project/clean_sales.sql\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to convert date formats\n",
    "def convert_date_format(date_str):\n",
    "    # Define possible date formats\n",
    "    formats = ['%d/%m/%Y', '%m/%d/%Y', '%Y/%m/%d']\n",
    "    \n",
    "    for fmt in formats:\n",
    "        try:\n",
    "            # Try to parse the date using the current format\n",
    "            return datetime.strptime(date_str, fmt).strftime('%Y-%m-%d')\n",
    "        except ValueError:\n",
    "            continue  # Try the next format if parsing fails\n",
    "    return None  # Return None if no format matched\n",
    "\n",
    "# Path to your CSV file\n",
    "csv_file_path = \"c:/users/rohit/downloads/project/clean_sales.csv\"\n",
    "\n",
    "# Read the CSV file and extract columns and values\n",
    "with open(csv_file_path, mode=\"r\", newline='', encoding='utf-8') as file:\n",
    "    csv_reader = csv.DictReader(file)\n",
    "    \n",
    "    # List of column names from the CSV\n",
    "    columns = csv_reader.fieldnames\n",
    "    columns_sql = ', '.join(columns)  # Convert column names to SQL format\n",
    "\n",
    "    # List to store the values for the INSERT query\n",
    "    values_list = []\n",
    "    \n",
    "    # Read each row and format the values for the SQL query\n",
    "    for row in csv_reader:\n",
    "        # Convert date fields to the correct format\n",
    "        for col in columns:\n",
    "            if 'Date' in col:  # Check if the column is a date column\n",
    "                converted_date = convert_date_format(row[col])\n",
    "                if converted_date is None:\n",
    "                    print(f\"Warning: Unable to convert date '{row[col]}' for row: {row}\")\n",
    "                    continue  # Skip this row or handle it as needed\n",
    "                row[col] = converted_date\n",
    "        \n",
    "        # Format values for SQL (Sales is treated differently if needed)\n",
    "        values = [f\"'{row[col]}'\" if col != \"Sales\" else row[col] for col in columns]\n",
    "        values_list.append(f\"({', '.join(values)})\")\n",
    "    \n",
    "    # Join all the rows' values with commas for a single INSERT statement\n",
    "    values_sql = ',\\n'.join(values_list)\n",
    "\n",
    "# Final SQL INSERT query\n",
    "insert_query = f\"INSERT INTO clean_sales ({columns_sql}) VALUES \\n{values_sql};\"\n",
    "\n",
    "# Save the SQL query to a file\n",
    "sql_file_path = \"c:/users/rohit/downloads/project/clean_sales.sql\"\n",
    "with open(sql_file_path, mode=\"w\", encoding='utf-8') as sql_file:\n",
    "    sql_file.write(insert_query)\n",
    "\n",
    "print(f\"SQL query generated and saved to: {sql_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6305b12d-b1d2-49cc-9dd1-bfe1a66273ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0302e87e-86d4-4d86-816c-f229cf6d8ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b6de14-cc6b-4ae2-b36f-f3dae91e0f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd143a1-55d8-48d8-9a73-a1343a792e00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66937efe-c2a9-4bee-9b0b-a700dc49b221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3728e1af-39e9-4c80-82b7-b99e20d2d979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a713e8ac-59e8-4fbe-a2c0-914d9093cff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c403a003-ba2e-4234-9861-f425a0c58843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd11c68b-f4fc-4ff3-bf91-e068abf489e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
